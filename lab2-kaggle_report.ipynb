{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip3 install gensim --upgrade\n",
    "#!pip3 install tensorflow --upgrade\n",
    "!pip3 install tensorflow==2.17.0\n",
    "#!pip3 install keras --upgrade\n",
    "!pip3 install keras==3.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T10:32:07.758457Z",
     "iopub.status.busy": "2024-12-03T10:32:07.758128Z",
     "iopub.status.idle": "2024-12-03T10:32:08.680302Z",
     "shell.execute_reply": "2024-12-03T10:32:08.679620Z",
     "shell.execute_reply.started": "2024-12-03T10:32:07.758432Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Preparation** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T10:32:11.816770Z",
     "iopub.status.busy": "2024-12-03T10:32:11.816295Z",
     "iopub.status.idle": "2024-12-03T10:32:41.067529Z",
     "shell.execute_reply": "2024-12-03T10:32:41.066769Z",
     "shell.execute_reply.started": "2024-12-03T10:32:11.816738Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Read data from kaggle dataset\n",
    "data = []\n",
    "with open('/kaggle/input/dm-2024-isa-5810-lab-2-homework/tweets_DM.json', 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    " \n",
    "f.close()\n",
    "\n",
    "emotion = pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/emotion.csv')\n",
    "data_identification = pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/data_identification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T10:33:16.210108Z",
     "iopub.status.busy": "2024-12-03T10:33:16.209618Z",
     "iopub.status.idle": "2024-12-03T10:33:27.360165Z",
     "shell.execute_reply": "2024-12-03T10:33:27.359350Z",
     "shell.execute_reply.started": "2024-12-03T10:33:16.210076Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# data transformation\n",
    "df = pd.DataFrame(data)\n",
    "_source = df['_source'].apply(lambda x: x['tweet'])\n",
    "df = pd.DataFrame({\n",
    "    'tweet_id': _source.apply(lambda x: x['tweet_id']),\n",
    "    'hashtags': _source.apply(lambda x: x['hashtags']),\n",
    "    'text': _source.apply(lambda x: x['text']),\n",
    "})\n",
    "df = df.merge(data_identification, on='tweet_id', how='left')\n",
    "\n",
    "# split data to train and test\n",
    "train_data = df[df['identification'] == 'train']\n",
    "test_data = df[df['identification'] == 'test']\n",
    "\n",
    "# drop the identification column\n",
    "train_data = train_data.drop(columns=['identification'])\n",
    "test_data = test_data.drop(columns=['identification'])\n",
    "\n",
    "# Merge emotion for corresponding tweet_id\n",
    "train_data = train_data.merge(emotion, on='tweet_id', how='left') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T10:33:30.953331Z",
     "iopub.status.busy": "2024-12-03T10:33:30.952597Z",
     "iopub.status.idle": "2024-12-03T10:33:31.060950Z",
     "shell.execute_reply": "2024-12-03T10:33:31.060053Z",
     "shell.execute_reply.started": "2024-12-03T10:33:30.953295Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1455563, 4)\n",
      "tweet_id    object\n",
      "hashtags    object\n",
      "text        object\n",
      "emotion     object\n",
      "dtype: object\n",
      "emotion\n",
      "joy             516017\n",
      "anticipation    248935\n",
      "trust           205478\n",
      "sadness         193437\n",
      "disgust         139101\n",
      "fear             63999\n",
      "surprise         48729\n",
      "anger            39867\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x376b20</td>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Now ISSA is stalking Tasha üòÇüòÇüòÇ &lt;LH&gt;</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1d755c</td>\n",
       "      <td>[authentic, LaughOutLoud]</td>\n",
       "      <td>@RISKshow @TheKevinAllison Thx for the BEST TI...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2c91a8</td>\n",
       "      <td>[]</td>\n",
       "      <td>Still waiting on those supplies Liscus. &lt;LH&gt;</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                       hashtags  \\\n",
       "0  0x376b20                     [Snapchat]   \n",
       "1  0x2d5350  [freepress, TrumpLegacy, CNN]   \n",
       "2  0x1cd5b0                             []   \n",
       "3  0x1d755c      [authentic, LaughOutLoud]   \n",
       "4  0x2c91a8                             []   \n",
       "\n",
       "                                                text       emotion  \n",
       "0  People who post \"add me on #Snapchat\" must be ...  anticipation  \n",
       "1  @brianklaas As we see, Trump is dangerous to #...       sadness  \n",
       "2                Now ISSA is stalking Tasha üòÇüòÇüòÇ <LH>          fear  \n",
       "3  @RISKshow @TheKevinAllison Thx for the BEST TI...           joy  \n",
       "4       Still waiting on those supplies Liscus. <LH>  anticipation  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print information\n",
    "print(train_data.shape)\n",
    "print(train_data.dtypes)\n",
    "print(train_data['emotion'].value_counts())\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T10:33:39.710710Z",
     "iopub.status.busy": "2024-12-03T10:33:39.709988Z",
     "iopub.status.idle": "2024-12-03T10:33:39.721313Z",
     "shell.execute_reply": "2024-12-03T10:33:39.720403Z",
     "shell.execute_reply.started": "2024-12-03T10:33:39.710673Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(411972, 3)\n",
      "tweet_id    object\n",
      "hashtags    object\n",
      "text        object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>[bibleverse]</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>[]</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0x218443</td>\n",
       "      <td>[materialism, money, possessions]</td>\n",
       "      <td>When do you have enough ? When are you satisfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0x2939d5</td>\n",
       "      <td>[GodsPlan, GodsWork]</td>\n",
       "      <td>God woke you up, now chase the day #GodsPlan #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0x26289a</td>\n",
       "      <td>[]</td>\n",
       "      <td>In these tough times, who do YOU turn to as yo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tweet_id                           hashtags  \\\n",
       "2   0x28b412                       [bibleverse]   \n",
       "4   0x2de201                                 []   \n",
       "9   0x218443  [materialism, money, possessions]   \n",
       "30  0x2939d5               [GodsPlan, GodsWork]   \n",
       "33  0x26289a                                 []   \n",
       "\n",
       "                                                 text  \n",
       "2   Confident of your obedience, I write to you, k...  \n",
       "4   \"Trust is not the same as faith. A friend is s...  \n",
       "9   When do you have enough ? When are you satisfi...  \n",
       "30  God woke you up, now chase the day #GodsPlan #...  \n",
       "33  In these tough times, who do YOU turn to as yo...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print information\n",
    "print(test_data.shape)\n",
    "print(test_data.dtypes)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T10:33:49.660440Z",
     "iopub.status.busy": "2024-12-03T10:33:49.659703Z",
     "iopub.status.idle": "2024-12-03T10:33:50.389425Z",
     "shell.execute_reply": "2024-12-03T10:33:50.388479Z",
     "shell.execute_reply.started": "2024-12-03T10:33:49.660403Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet_id    {'Missing Values': 0, 'Total Count': 1455563, ...\n",
      "hashtags    {'Missing Values': 0, 'Total Count': 1455563, ...\n",
      "text        {'Missing Values': 0, 'Total Count': 1455563, ...\n",
      "emotion     {'Missing Values': 0, 'Total Count': 1455563, ...\n",
      "dtype: object\n",
      "tweet_id    {'Missing Values': 0, 'Total Count': 411972, '...\n",
      "hashtags    {'Missing Values': 0, 'Total Count': 411972, '...\n",
      "text        {'Missing Values': 0, 'Total Count': 411972, '...\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Dealing with Missing data\n",
    "def check_missing_values(series):\n",
    "    \"\"\"\n",
    "    Check missing values in a Series\n",
    "    \n",
    "    Args:\n",
    "        series: pandas Series object\n",
    "        \n",
    "    Returns:\n",
    "        dict: dictionary containing missing value statistics\n",
    "    \"\"\"\n",
    "    missing_count = series.isnull().sum()\n",
    "    total_count = len(series)\n",
    "    missing_percentage = (missing_count / total_count) * 100\n",
    "    \n",
    "    return {\n",
    "        'Missing Values': missing_count,\n",
    "        'Total Count': total_count,\n",
    "        'Missing Percentage(%)': round(missing_percentage, 2)\n",
    "    }\n",
    "\n",
    "# Check missing values for each column\n",
    "missing_train = train_data.apply(check_missing_values)\n",
    "missing_test = test_data.apply(check_missing_values)\n",
    "\n",
    "print(missing_train)\n",
    "print(missing_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T10:33:53.149594Z",
     "iopub.status.busy": "2024-12-03T10:33:53.149247Z",
     "iopub.status.idle": "2024-12-03T10:33:54.252777Z",
     "shell.execute_reply": "2024-12-03T10:33:54.252019Z",
     "shell.execute_reply.started": "2024-12-03T10:33:53.149565Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Dealing with Duplicate Data\n",
    "sum(train_data.duplicated('text')) \n",
    "train_data.drop_duplicates(subset=['text'], keep=False, inplace=True) # Remove duplication = 1449182"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T10:34:11.769370Z",
     "iopub.status.busy": "2024-12-03T10:34:11.768669Z",
     "iopub.status.idle": "2024-12-03T10:34:19.951807Z",
     "shell.execute_reply": "2024-12-03T10:34:19.950600Z",
     "shell.execute_reply.started": "2024-12-03T10:34:11.769336Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in /opt/conda/lib/python3.10/site-packages (2.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install emoji\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T10:34:23.081610Z",
     "iopub.status.busy": "2024-12-03T10:34:23.081239Z",
     "iopub.status.idle": "2024-12-03T10:37:47.226449Z",
     "shell.execute_reply": "2024-12-03T10:37:47.225437Z",
     "shell.execute_reply.started": "2024-12-03T10:34:23.081577Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Clean and standardize text\n",
    "import re\n",
    "import emoji\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean and standardize text\n",
    "    \"\"\"\n",
    "    #switch emoji to text\n",
    "    text = emoji.demojize(text, delimiters=[\":\", \":\"])\n",
    "    # Convert to lowercase\n",
    "    text = str(text).lower()\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    # Remove @mentions\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^\\w\\s_]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Preprocess both text and hashtags using the same cleaning function\n",
    "    \"\"\"\n",
    "    # Clean text\n",
    "    df['cleaned_text'] = df['text'].apply(clean_text)\n",
    "    \n",
    "    # Clean hashtags - convert list to string and clean\n",
    "    df['cleaned_hashtags'] = df['hashtags'].apply(lambda x: clean_text(' '.join(x) if isinstance(x, list) else ''))\n",
    "    \n",
    "    # Combine text and hashtags\n",
    "    df['combined_text'] = df.apply(lambda x: \n",
    "        x['cleaned_text'] + ' ' + x['cleaned_hashtags'], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "processed_train = preprocess_data(train_data)\n",
    "processed_test = preprocess_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T10:38:25.807583Z",
     "iopub.status.busy": "2024-12-03T10:38:25.807201Z",
     "iopub.status.idle": "2024-12-03T10:38:26.003534Z",
     "shell.execute_reply": "2024-12-03T10:38:26.002712Z",
     "shell.execute_reply.started": "2024-12-03T10:38:25.807554Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144918, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sampling Only using 10% of data \n",
    "train_data_sample = processed_train.sample(frac=0.1) # Get sample\n",
    "train_data_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Feature engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **BOW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T10:46:03.407950Z",
     "iopub.status.busy": "2024-12-03T10:46:03.407297Z",
     "iopub.status.idle": "2024-12-03T10:51:38.324470Z",
     "shell.execute_reply": "2024-12-03T10:51:38.323569Z",
     "shell.execute_reply.started": "2024-12-03T10:46:03.407891Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1449182, 500)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# build analyzers (bag-of-words)\n",
    "BOW_500 = CountVectorizer(max_features=500, tokenizer=nltk.word_tokenize) \n",
    "\n",
    "# apply analyzer to training data\n",
    "BOW_500.fit(processed_train['combined_text'])\n",
    "train_data_BOW_features_500 = BOW_500.transform(processed_train['combined_text'])\n",
    "\n",
    "## check dimension\n",
    "train_data_BOW_features_500.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T10:39:10.238234Z",
     "iopub.status.busy": "2024-12-03T10:39:10.237841Z",
     "iopub.status.idle": "2024-12-03T10:39:29.618561Z",
     "shell.execute_reply": "2024-12-03T10:39:29.617650Z",
     "shell.execute_reply.started": "2024-12-03T10:39:10.238195Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1449182, 1000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# ‰ΩøÁî® TfidfVectorizer ÁîüÊàê TF-IDF ÂµåÂÖ•\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "train_data_tfidf_matrix_1000 = vectorizer.fit_transform(processed_train['combined_text'])\n",
    "\n",
    "## check dimension\n",
    "train_data_tfidf_matrix_1000.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Word2Vec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T11:31:14.769749Z",
     "iopub.status.busy": "2024-12-03T11:31:14.769394Z",
     "iopub.status.idle": "2024-12-03T11:40:02.461277Z",
     "shell.execute_reply": "2024-12-03T11:40:02.460556Z",
     "shell.execute_reply.started": "2024-12-03T11:31:14.769723Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## check library\n",
    "import gensim\n",
    "\n",
    "## ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# # if you want to see the training messages, you can use it\n",
    "# import logging\n",
    "# logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "## the input type\n",
    "processed_train['text_tokenized'] = processed_train['combined_text'].apply(lambda x: nltk.word_tokenize(x))\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "## create the training corpus\n",
    "training_corpus = processed_train['text_tokenized'].values\n",
    "training_corpus[:3]\n",
    "\n",
    "## setting\n",
    "vector_dim = 100\n",
    "window_size = 5\n",
    "min_count = 1\n",
    "training_epochs = 20\n",
    "\n",
    "## model\n",
    "word2vec_model = Word2Vec(sentences=training_corpus, \n",
    "                          vector_size=vector_dim, window=window_size, \n",
    "                          min_count=min_count, epochs=training_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T12:39:03.019251Z",
     "iopub.status.busy": "2024-12-03T12:39:03.018509Z",
     "iopub.status.idle": "2024-12-03T12:42:30.862642Z",
     "shell.execute_reply": "2024-12-03T12:42:30.861911Z",
     "shell.execute_reply.started": "2024-12-03T12:39:03.019208Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def text_to_avg_vector(tokens, model):\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
    "# Â∞áÊñáÊú¨ËΩâÊèõÁÇ∫ÂêëÈáè\n",
    "processed_train['text_tokenized'] = processed_train['combined_text'].apply(lambda x: text_to_avg_vector(x, word2vec_model))\n",
    "X = np.array(processed_train['text_tokenized'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Naive Bayes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOW 10%sample: Mean F1-Score: 0.2759809569012269  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T11:20:35.639016Z",
     "iopub.status.busy": "2024-12-03T11:20:35.638608Z",
     "iopub.status.idle": "2024-12-03T11:20:36.444142Z",
     "shell.execute_reply": "2024-12-03T11:20:36.443249Z",
     "shell.execute_reply.started": "2024-12-03T11:20:35.638983Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (1159345, 500)\n",
      "y_train.shape:  (1159345,)\n",
      "X_test.shape:  (289837, 500)\n",
      "y_test.shape:  (289837,)\n"
     ]
    }
   ],
   "source": [
    "#Prepare train data and one hot encoding_\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# for a classificaiton problem, you need to provide both training & testing data\n",
    "X_train_data = train_data_BOW_features_500\n",
    "y_train_data = processed_train['emotion']\n",
    "\n",
    "le = LabelEncoder() # Label target\n",
    "y_train_le = le.fit_transform(y_train_data)\n",
    "\n",
    "# Split training and testing data for evaluation.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_data, y_train_le, test_size=0.2, random_state=42, stratify=y_train_le) \n",
    "\n",
    "#check dimension is a good habbit \n",
    "print('X_train.shape: ', X_train.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('X_test.shape: ', X_test.shape)\n",
    "print('y_test.shape: ', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T11:20:40.479545Z",
     "iopub.status.busy": "2024-12-03T11:20:40.479235Z",
     "iopub.status.idle": "2024-12-03T11:20:40.790985Z",
     "shell.execute_reply": "2024-12-03T11:20:40.790275Z",
     "shell.execute_reply.started": "2024-12-03T11:20:40.479518Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# Ë®ìÁ∑¥ Naive Bayes Ê®°Âûã\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# È†êÊ∏¨Ê∏¨Ë©¶ÈõÜ\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T11:20:42.928210Z",
     "iopub.status.busy": "2024-12-03T11:20:42.927877Z",
     "iopub.status.idle": "2024-12-03T11:20:43.238757Z",
     "shell.execute_reply": "2024-12-03T11:20:43.237932Z",
     "shell.execute_reply.started": "2024-12-03T11:20:42.928179Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.07      0.10      7916\n",
      "           1       0.46      0.43      0.44     49705\n",
      "           2       0.29      0.25      0.27     27785\n",
      "           3       0.21      0.12      0.16     12740\n",
      "           4       0.47      0.65      0.55    102636\n",
      "           5       0.31      0.33      0.32     38610\n",
      "           6       0.28      0.07      0.12      9542\n",
      "           7       0.36      0.20      0.25     40903\n",
      "\n",
      "    accuracy                           0.41    289837\n",
      "   macro avg       0.32      0.27      0.28    289837\n",
      "weighted avg       0.39      0.41      0.39    289837\n",
      "\n",
      "Mean F1-Score: 0.2759809569012269\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred) \n",
    "\n",
    "## precision, recall, f1-score,\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred))\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"Mean F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOW whole train dataset: Accuracy: 0.41043334253381175  \n",
    "Kaggle score:0.31649 (The best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# for a classificaiton problem, you need to provide both training & testing data\n",
    "X_train_data = train_data_BOW_features_500\n",
    "y_train_data = train_data_sample['emotion']\n",
    "\n",
    "le = LabelEncoder() # Label target\n",
    "y_train_le = le.fit_transform(y_train_data)\n",
    "\n",
    "# Split training and testing data for evaluation.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_data, y_train_le, test_size=0.3, random_state=42, stratify=y_train_le) \n",
    "\n",
    "#check dimension is a good habbit \n",
    "print('X_train.shape: ', X_train.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('X_test.shape: ', X_test.shape)\n",
    "print('y_test.shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# train Naive Bayes model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred) # Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply analyzer to training data\n",
    "test_data_BOW_features_500 = BOW_500.transform(processed_test['combined_text'])\n",
    "X_test_data = test_data_BOW_features_500\n",
    "y_pred = model.predict(X_test_data)\n",
    "# Inverse predict labels back to adjective words\n",
    "y_pred_labels = le.inverse_transform(y_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF Whole train dataset: Mean F1-Score: 0.2609319258751323  \n",
    "Kaggle score: 0.18776"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T11:20:54.375894Z",
     "iopub.status.busy": "2024-12-03T11:20:54.375541Z",
     "iopub.status.idle": "2024-12-03T11:20:55.156514Z",
     "shell.execute_reply": "2024-12-03T11:20:55.155548Z",
     "shell.execute_reply.started": "2024-12-03T11:20:54.375846Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (1159345, 1000)\n",
      "y_train.shape:  (1159345,)\n",
      "X_test.shape:  (289837, 1000)\n",
      "y_test.shape:  (289837,)\n"
     ]
    }
   ],
   "source": [
    "#Prepare train data and one hot encoding_TF-IDF: Mean F1-Score: 0.2609319258751323\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# for a classificaiton problem, you need to provide both training & testing data\n",
    "X_train_data = train_data_tfidf_matrix_1000\n",
    "y_train_data = processed_train['emotion']\n",
    "\n",
    "le = LabelEncoder() # Label target\n",
    "y_train_le = le.fit_transform(y_train_data)\n",
    "\n",
    "# Split training and testing data for evaluation.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_data, y_train_le, test_size=0.2, random_state=42, stratify=y_train_le) \n",
    "\n",
    "#check dimension is a good habbit \n",
    "print('X_train.shape: ', X_train.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('X_test.shape: ', X_test.shape)\n",
    "print('y_test.shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T11:21:00.892302Z",
     "iopub.status.busy": "2024-12-03T11:21:00.891949Z",
     "iopub.status.idle": "2024-12-03T11:21:01.201868Z",
     "shell.execute_reply": "2024-12-03T11:21:01.201158Z",
     "shell.execute_reply.started": "2024-12-03T11:21:00.892273Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# train Naive Bayes model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T11:21:02.783717Z",
     "iopub.status.busy": "2024-12-03T11:21:02.783156Z",
     "iopub.status.idle": "2024-12-03T11:21:03.304554Z",
     "shell.execute_reply": "2024-12-03T11:21:03.303695Z",
     "shell.execute_reply.started": "2024-12-03T11:21:02.783684Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.00      0.00      7916\n",
      "           1       0.59      0.37      0.46     49705\n",
      "           2       0.50      0.13      0.21     27785\n",
      "           3       0.79      0.16      0.26     12740\n",
      "           4       0.42      0.90      0.57    102636\n",
      "           5       0.43      0.26      0.33     38610\n",
      "           6       0.74      0.06      0.11      9542\n",
      "           7       0.64      0.09      0.15     40903\n",
      "\n",
      "    accuracy                           0.45    289837\n",
      "   macro avg       0.58      0.25      0.26    289837\n",
      "weighted avg       0.52      0.45      0.38    289837\n",
      "\n",
      "Mean F1-Score: 0.2609319258751323\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred) \n",
    "\n",
    "## precision, recall, f1-score,\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred))\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"Mean F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF whole train dataset, under sampling: Mean F1-Score: 0.35301556270571005  \n",
    "Kaggle score: 0.12878 (ÊúâÂö¥ÈáçÁöÑoverfittingÂïèÈ°å)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF whole train dataset, over sampling: Mean F1-Score: 0.3590395043436134  \n",
    "Kaggle score: 0.12619 (ÊúâÂö¥ÈáçÁöÑoverfittingÂïèÈ°å)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF 1000 features\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "train_data_tfidf_matrix_1000 = vectorizer.fit_transform(processed_train['combined_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "le = LabelEncoder()\n",
    "y_train_data = processed_train['emotion']\n",
    "y_train_le = le.fit_transform(y_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# under sampling for imbalanced data\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(train_data_tfidf_matrix_1000, y_train_le)\n",
    "\n",
    "# divede data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train Naive Bayes model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred) \n",
    "\n",
    "## precision, recall, f1-score,\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred))\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"Mean F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply analyzer to training data\n",
    "test_data_tfidf_matrix_1000 = vectorizer.fit_transform(processed_test['combined_text'])\n",
    "# for a classificaiton problem, you need to provide both training & testing data\n",
    "X_test_data = test_data_tfidf_matrix_1000\n",
    "# predict test set\n",
    "y_pred = model.predict(X_test_data)\n",
    "\n",
    "# Inverse predict labels back to adjective words\n",
    "y_pred_labels = le.inverse_transform(y_pred) \n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': processed_test['tweet_id'],\n",
    "    'emotion': y_pred_labels\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('/kaggle/working/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **RandomForest**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOW Mean F1-Score: 0.3396583541292876"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ë®ìÁ∑¥RandomForestClassifierÊ®°Âûã \n",
    "# BOW Mean F1-Score: 0.3396583541292876\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# È†êÊ∏¨\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Ë©ï‰º∞\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Mean F1-Score:\", f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec Mean F1-Score: 0.17355334788122762\n",
    "Kaggle score: 0.18184"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare train data and one hot encoding_Word2vec: Mean F1-Score: 0.19585560764574117 \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# for a classificaiton problem, you need to provide both training & testing data\n",
    "X_train_data = X\n",
    "y_train_data = train_data_sample['emotion']\n",
    "\n",
    "le = LabelEncoder () # Label target\n",
    "y_train_le = le.fit_transform(y_train_data)\n",
    "\n",
    "# Split training and testing data for evaluation.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_data, y_train_le, test_size=0.2, random_state=42, stratify=y_train_le) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Ë®ìÁ∑¥Ê®°Âûã\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# È†êÊ∏¨Ê∏¨Ë©¶ÈõÜ\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred) \n",
    "\n",
    "## precision, recall, f1-score,\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred))\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"Mean F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **KNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOW 10% sampling Mean F1-Score: 0.2920292796144408\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "print(\"KNN Model\")\n",
    "print(accuracy_score(y_test, y_pred_knn))\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "print(\"Mean F1-Score:\", f1_score(y_test, y_pred_knn, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **testing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T08:15:14.405627Z",
     "iopub.status.busy": "2024-12-03T08:15:14.404844Z",
     "iopub.status.idle": "2024-12-03T08:15:14.493810Z",
     "shell.execute_reply": "2024-12-03T08:15:14.492762Z",
     "shell.execute_reply.started": "2024-12-03T08:15:14.405592Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# apply analyzer to training data\n",
    "test_data_BOW_features_500 = BOW_500.transform(processed_test['combined_text'])\n",
    "# for a classificaiton problem, you need to provide both training & testing data\n",
    "X_test_data = test_data_BOW_features_500\n",
    "y_pred = model.predict(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T08:16:14.164275Z",
     "iopub.status.busy": "2024-12-03T08:16:14.163905Z",
     "iopub.status.idle": "2024-12-03T08:16:14.179891Z",
     "shell.execute_reply": "2024-12-03T08:16:14.179255Z",
     "shell.execute_reply.started": "2024-12-03T08:16:14.164246Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Inverse predict labels back to adjective words\n",
    "y_pred_labels = le.inverse_transform(y_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T08:17:26.695464Z",
     "iopub.status.busy": "2024-12-03T08:17:26.695105Z",
     "iopub.status.idle": "2024-12-03T08:17:26.715349Z",
     "shell.execute_reply": "2024-12-03T08:17:26.714672Z",
     "shell.execute_reply.started": "2024-12-03T08:17:26.695416Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'id': processed_test['tweet_id'],\n",
    "    'emotion': y_pred_labels\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T08:17:39.133535Z",
     "iopub.status.busy": "2024-12-03T08:17:39.133188Z",
     "iopub.status.idle": "2024-12-03T08:17:39.542466Z",
     "shell.execute_reply": "2024-12-03T08:17:39.541726Z",
     "shell.execute_reply.started": "2024-12-03T08:17:39.133505Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('/kaggle/working/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T08:18:16.434891Z",
     "iopub.status.busy": "2024-12-03T08:18:16.434549Z",
     "iopub.status.idle": "2024-12-03T08:18:16.444762Z",
     "shell.execute_reply": "2024-12-03T08:18:16.443774Z",
     "shell.execute_reply.started": "2024-12-03T08:18:16.434862Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9912598,
     "sourceId": 87232,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
