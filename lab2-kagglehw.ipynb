{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2e0a53c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T09:15:31.806672Z",
     "iopub.status.busy": "2024-12-08T09:15:31.806130Z",
     "iopub.status.idle": "2024-12-08T09:15:35.257004Z",
     "shell.execute_reply": "2024-12-08T09:15:35.255709Z"
    },
    "papermill": {
     "duration": 3.462054,
     "end_time": "2024-12-08T09:15:35.260100",
     "exception": false,
     "start_time": "2024-12-08T09:15:31.798046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489b9b48",
   "metadata": {
    "papermill": {
     "duration": 0.007887,
     "end_time": "2024-12-08T09:15:35.277729",
     "exception": false,
     "start_time": "2024-12-08T09:15:35.269842",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Data Preparation** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ce4f40e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T09:15:35.296656Z",
     "iopub.status.busy": "2024-12-08T09:15:35.295046Z",
     "iopub.status.idle": "2024-12-08T09:16:11.117002Z",
     "shell.execute_reply": "2024-12-08T09:16:11.115501Z"
    },
    "papermill": {
     "duration": 35.835261,
     "end_time": "2024-12-08T09:16:11.120104",
     "exception": false,
     "start_time": "2024-12-08T09:15:35.284843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read data from kaggle dataset\n",
    "data = []\n",
    "with open('/kaggle/input/dm-2024-isa-5810-lab-2-homework/tweets_DM.json', 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    " \n",
    "f.close()\n",
    "\n",
    "emotion = pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/emotion.csv')\n",
    "data_identification = pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/data_identification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "889f3155",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T09:16:11.135650Z",
     "iopub.status.busy": "2024-12-08T09:16:11.135220Z",
     "iopub.status.idle": "2024-12-08T09:16:25.263718Z",
     "shell.execute_reply": "2024-12-08T09:16:25.262418Z"
    },
    "papermill": {
     "duration": 14.138911,
     "end_time": "2024-12-08T09:16:25.266731",
     "exception": false,
     "start_time": "2024-12-08T09:16:11.127820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data transformation\n",
    "df = pd.DataFrame(data)\n",
    "_source = df['_source'].apply(lambda x: x['tweet'])\n",
    "df = pd.DataFrame({\n",
    "    'tweet_id': _source.apply(lambda x: x['tweet_id']),\n",
    "    'hashtags': _source.apply(lambda x: x['hashtags']),\n",
    "    'text': _source.apply(lambda x: x['text']),\n",
    "})\n",
    "df = df.merge(data_identification, on='tweet_id', how='left')\n",
    "\n",
    "# split data to train and test\n",
    "train_data = df[df['identification'] == 'train']\n",
    "test_data = df[df['identification'] == 'test']\n",
    "\n",
    "# drop the identification column\n",
    "train_data = train_data.drop(columns=['identification'])\n",
    "test_data = test_data.drop(columns=['identification'])\n",
    "\n",
    "# Merge emotion for corresponding tweet_id\n",
    "train_data = train_data.merge(emotion, on='tweet_id', how='left') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53e3ccc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T09:16:25.287544Z",
     "iopub.status.busy": "2024-12-08T09:16:25.287142Z",
     "iopub.status.idle": "2024-12-08T09:16:25.431225Z",
     "shell.execute_reply": "2024-12-08T09:16:25.429820Z"
    },
    "papermill": {
     "duration": 0.158569,
     "end_time": "2024-12-08T09:16:25.435477",
     "exception": false,
     "start_time": "2024-12-08T09:16:25.276908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1455563, 4)\n",
      "tweet_id    object\n",
      "hashtags    object\n",
      "text        object\n",
      "emotion     object\n",
      "dtype: object\n",
      "emotion\n",
      "joy             516017\n",
      "anticipation    248935\n",
      "trust           205478\n",
      "sadness         193437\n",
      "disgust         139101\n",
      "fear             63999\n",
      "surprise         48729\n",
      "anger            39867\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x376b20</td>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Now ISSA is stalking Tasha üòÇüòÇüòÇ &lt;LH&gt;</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1d755c</td>\n",
       "      <td>[authentic, LaughOutLoud]</td>\n",
       "      <td>@RISKshow @TheKevinAllison Thx for the BEST TI...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2c91a8</td>\n",
       "      <td>[]</td>\n",
       "      <td>Still waiting on those supplies Liscus. &lt;LH&gt;</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                       hashtags  \\\n",
       "0  0x376b20                     [Snapchat]   \n",
       "1  0x2d5350  [freepress, TrumpLegacy, CNN]   \n",
       "2  0x1cd5b0                             []   \n",
       "3  0x1d755c      [authentic, LaughOutLoud]   \n",
       "4  0x2c91a8                             []   \n",
       "\n",
       "                                                text       emotion  \n",
       "0  People who post \"add me on #Snapchat\" must be ...  anticipation  \n",
       "1  @brianklaas As we see, Trump is dangerous to #...       sadness  \n",
       "2                Now ISSA is stalking Tasha üòÇüòÇüòÇ <LH>          fear  \n",
       "3  @RISKshow @TheKevinAllison Thx for the BEST TI...           joy  \n",
       "4       Still waiting on those supplies Liscus. <LH>  anticipation  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print information\n",
    "print(train_data.shape)\n",
    "print(train_data.dtypes)\n",
    "print(train_data['emotion'].value_counts())\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ee492e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T09:16:25.460598Z",
     "iopub.status.busy": "2024-12-08T09:16:25.460076Z",
     "iopub.status.idle": "2024-12-08T09:16:25.481637Z",
     "shell.execute_reply": "2024-12-08T09:16:25.480640Z"
    },
    "papermill": {
     "duration": 0.039236,
     "end_time": "2024-12-08T09:16:25.486176",
     "exception": false,
     "start_time": "2024-12-08T09:16:25.446940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(411972, 3)\n",
      "tweet_id    object\n",
      "hashtags    object\n",
      "text        object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>[bibleverse]</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>[]</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0x218443</td>\n",
       "      <td>[materialism, money, possessions]</td>\n",
       "      <td>When do you have enough ? When are you satisfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0x2939d5</td>\n",
       "      <td>[GodsPlan, GodsWork]</td>\n",
       "      <td>God woke you up, now chase the day #GodsPlan #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0x26289a</td>\n",
       "      <td>[]</td>\n",
       "      <td>In these tough times, who do YOU turn to as yo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tweet_id                           hashtags  \\\n",
       "2   0x28b412                       [bibleverse]   \n",
       "4   0x2de201                                 []   \n",
       "9   0x218443  [materialism, money, possessions]   \n",
       "30  0x2939d5               [GodsPlan, GodsWork]   \n",
       "33  0x26289a                                 []   \n",
       "\n",
       "                                                 text  \n",
       "2   Confident of your obedience, I write to you, k...  \n",
       "4   \"Trust is not the same as faith. A friend is s...  \n",
       "9   When do you have enough ? When are you satisfi...  \n",
       "30  God woke you up, now chase the day #GodsPlan #...  \n",
       "33  In these tough times, who do YOU turn to as yo...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print information\n",
    "print(test_data.shape)\n",
    "print(test_data.dtypes)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffdb597",
   "metadata": {
    "papermill": {
     "duration": 0.013368,
     "end_time": "2024-12-08T09:16:25.513502",
     "exception": false,
     "start_time": "2024-12-08T09:16:25.500134",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ff9b03a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T09:16:25.534233Z",
     "iopub.status.busy": "2024-12-08T09:16:25.533681Z",
     "iopub.status.idle": "2024-12-08T09:16:26.401332Z",
     "shell.execute_reply": "2024-12-08T09:16:26.399940Z"
    },
    "papermill": {
     "duration": 0.881421,
     "end_time": "2024-12-08T09:16:26.404407",
     "exception": false,
     "start_time": "2024-12-08T09:16:25.522986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet_id    {'Missing Values': 0, 'Total Count': 1455563, ...\n",
      "hashtags    {'Missing Values': 0, 'Total Count': 1455563, ...\n",
      "text        {'Missing Values': 0, 'Total Count': 1455563, ...\n",
      "emotion     {'Missing Values': 0, 'Total Count': 1455563, ...\n",
      "dtype: object\n",
      "tweet_id    {'Missing Values': 0, 'Total Count': 411972, '...\n",
      "hashtags    {'Missing Values': 0, 'Total Count': 411972, '...\n",
      "text        {'Missing Values': 0, 'Total Count': 411972, '...\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Dealing with Missing data\n",
    "def check_missing_values(series):\n",
    "    \"\"\"\n",
    "    Check missing values in a Series\n",
    "    \n",
    "    Args:\n",
    "        series: pandas Series object\n",
    "        \n",
    "    Returns:\n",
    "        dict: dictionary containing missing value statistics\n",
    "    \"\"\"\n",
    "    missing_count = series.isnull().sum()\n",
    "    total_count = len(series)\n",
    "    missing_percentage = (missing_count / total_count) * 100\n",
    "    \n",
    "    return {\n",
    "        'Missing Values': missing_count,\n",
    "        'Total Count': total_count,\n",
    "        'Missing Percentage(%)': round(missing_percentage, 2)\n",
    "    }\n",
    "\n",
    "# Check missing values for each column\n",
    "missing_train = train_data.apply(check_missing_values)\n",
    "missing_test = test_data.apply(check_missing_values)\n",
    "\n",
    "print(missing_train)\n",
    "print(missing_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1df2491",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T09:16:26.419347Z",
     "iopub.status.busy": "2024-12-08T09:16:26.418982Z",
     "iopub.status.idle": "2024-12-08T09:16:27.893909Z",
     "shell.execute_reply": "2024-12-08T09:16:27.892862Z"
    },
    "papermill": {
     "duration": 1.485331,
     "end_time": "2024-12-08T09:16:27.896396",
     "exception": false,
     "start_time": "2024-12-08T09:16:26.411065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Dealing with Duplicate Data\n",
    "sum(train_data.duplicated('text')) \n",
    "train_data.drop_duplicates(subset=['text'], keep=False, inplace=True) # Remove duplication = 1449182"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe2d755d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T09:16:27.910174Z",
     "iopub.status.busy": "2024-12-08T09:16:27.909810Z",
     "iopub.status.idle": "2024-12-08T09:16:41.051677Z",
     "shell.execute_reply": "2024-12-08T09:16:41.050108Z"
    },
    "papermill": {
     "duration": 13.151741,
     "end_time": "2024-12-08T09:16:41.054181",
     "exception": false,
     "start_time": "2024-12-08T09:16:27.902440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in /opt/conda/lib/python3.10/site-packages (2.14.0)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install emoji\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be8747cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T09:16:41.068924Z",
     "iopub.status.busy": "2024-12-08T09:16:41.068367Z",
     "iopub.status.idle": "2024-12-08T09:20:49.341288Z",
     "shell.execute_reply": "2024-12-08T09:20:49.340045Z"
    },
    "papermill": {
     "duration": 248.283564,
     "end_time": "2024-12-08T09:20:49.344090",
     "exception": false,
     "start_time": "2024-12-08T09:16:41.060526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Clean and standardize text\n",
    "import re\n",
    "import emoji\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean and standardize text\n",
    "    \"\"\"\n",
    "    #switch emoji to text\n",
    "    text = emoji.demojize(text, delimiters=[\":\", \":\"])\n",
    "    # Convert to lowercase\n",
    "    text = str(text).lower()\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    # Remove @mentions\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^\\w\\s_]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Preprocess both text and hashtags using the same cleaning function\n",
    "    \"\"\"\n",
    "    # Clean text\n",
    "    df['cleaned_text'] = df['text'].apply(clean_text)\n",
    "    \n",
    "    # Clean hashtags - convert list to string and clean\n",
    "    df['cleaned_hashtags'] = df['hashtags'].apply(lambda x: clean_text(' '.join(x) if isinstance(x, list) else ''))\n",
    "    \n",
    "    # Combine text and hashtags\n",
    "    df['combined_text'] = df.apply(lambda x: \n",
    "        x['cleaned_text'] + ' ' + x['cleaned_hashtags'], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "processed_train = preprocess_data(train_data)\n",
    "processed_test = preprocess_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1deac06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T09:20:49.359577Z",
     "iopub.status.busy": "2024-12-08T09:20:49.358606Z",
     "iopub.status.idle": "2024-12-08T09:20:49.639860Z",
     "shell.execute_reply": "2024-12-08T09:20:49.638767Z"
    },
    "papermill": {
     "duration": 0.291122,
     "end_time": "2024-12-08T09:20:49.642031",
     "exception": false,
     "start_time": "2024-12-08T09:20:49.350909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144918, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sampling Only using 10% of data \n",
    "train_data_sample = processed_train.sample(frac=0.1) # Get sample\n",
    "train_data_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933c4aca",
   "metadata": {
    "papermill": {
     "duration": 0.006083,
     "end_time": "2024-12-08T09:20:49.654437",
     "exception": false,
     "start_time": "2024-12-08T09:20:49.648354",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Feature engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ba021a",
   "metadata": {
    "papermill": {
     "duration": 0.00576,
     "end_time": "2024-12-08T09:20:49.666159",
     "exception": false,
     "start_time": "2024-12-08T09:20:49.660399",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**BOW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d05afbe9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T09:20:49.680498Z",
     "iopub.status.busy": "2024-12-08T09:20:49.679612Z",
     "iopub.status.idle": "2024-12-08T09:21:31.385166Z",
     "shell.execute_reply": "2024-12-08T09:21:31.383950Z"
    },
    "papermill": {
     "duration": 41.721186,
     "end_time": "2024-12-08T09:21:31.393372",
     "exception": false,
     "start_time": "2024-12-08T09:20:49.672186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(144918, 500)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# build analyzers (bag-of-words)\n",
    "BOW_500 = CountVectorizer(max_features=500, tokenizer=nltk.word_tokenize) \n",
    "\n",
    "# apply analyzer to training data\n",
    "BOW_500.fit(train_data_sample['combined_text'])\n",
    "train_data_BOW_features_500 = BOW_500.transform(train_data_sample['combined_text'])\n",
    "\n",
    "## check dimension\n",
    "train_data_BOW_features_500.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c967531",
   "metadata": {
    "papermill": {
     "duration": 0.006083,
     "end_time": "2024-12-08T09:21:31.405721",
     "exception": false,
     "start_time": "2024-12-08T09:21:31.399638",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Prepare train data and one hot encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be707816",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T09:21:31.420422Z",
     "iopub.status.busy": "2024-12-08T09:21:31.419988Z",
     "iopub.status.idle": "2024-12-08T09:21:31.526230Z",
     "shell.execute_reply": "2024-12-08T09:21:31.525022Z"
    },
    "papermill": {
     "duration": 0.116587,
     "end_time": "2024-12-08T09:21:31.528655",
     "exception": false,
     "start_time": "2024-12-08T09:21:31.412068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (101442, 500)\n",
      "y_train.shape:  (101442,)\n",
      "X_test.shape:  (43476, 500)\n",
      "y_test.shape:  (43476,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# for a classificaiton problem, you need to provide both training & testing data\n",
    "X_train_data = train_data_BOW_features_500\n",
    "y_train_data = train_data_sample['emotion']\n",
    "\n",
    "le = LabelEncoder() # Label target\n",
    "y_train_le = le.fit_transform(y_train_data)\n",
    "\n",
    "# Split training and testing data for evaluation.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_data, y_train_le, test_size=0.3, random_state=42, stratify=y_train_le) \n",
    "\n",
    "#check dimension is a good habbit \n",
    "print('X_train.shape: ', X_train.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('X_test.shape: ', X_test.shape)\n",
    "print('y_test.shape: ', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d112d7",
   "metadata": {
    "papermill": {
     "duration": 0.006492,
     "end_time": "2024-12-08T09:21:31.542182",
     "exception": false,
     "start_time": "2024-12-08T09:21:31.535690",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91159140",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T09:21:31.557294Z",
     "iopub.status.busy": "2024-12-08T09:21:31.556924Z",
     "iopub.status.idle": "2024-12-08T09:21:31.610204Z",
     "shell.execute_reply": "2024-12-08T09:21:31.609166Z"
    },
    "papermill": {
     "duration": 0.063721,
     "end_time": "2024-12-08T09:21:31.612748",
     "exception": false,
     "start_time": "2024-12-08T09:21:31.549027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# Ë®ìÁ∑¥ Naive Bayes Ê®°Âûã\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# È†êÊ∏¨Ê∏¨Ë©¶ÈõÜ\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a53e03",
   "metadata": {
    "papermill": {
     "duration": 0.006173,
     "end_time": "2024-12-08T09:21:31.625468",
     "exception": false,
     "start_time": "2024-12-08T09:21:31.619295",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Results evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9f3141d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T09:21:31.640510Z",
     "iopub.status.busy": "2024-12-08T09:21:31.640111Z",
     "iopub.status.idle": "2024-12-08T09:21:31.650472Z",
     "shell.execute_reply": "2024-12-08T09:21:31.649398Z"
    },
    "papermill": {
     "duration": 0.020693,
     "end_time": "2024-12-08T09:21:31.652605",
     "exception": false,
     "start_time": "2024-12-08T09:21:31.631912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41098537123930445"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred) # Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41475bf1",
   "metadata": {
    "papermill": {
     "duration": 0.006158,
     "end_time": "2024-12-08T09:21:31.665454",
     "exception": false,
     "start_time": "2024-12-08T09:21:31.659296",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **testing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "644ed1d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T09:21:31.680376Z",
     "iopub.status.busy": "2024-12-08T09:21:31.679970Z",
     "iopub.status.idle": "2024-12-08T09:22:31.974033Z",
     "shell.execute_reply": "2024-12-08T09:22:31.972775Z"
    },
    "papermill": {
     "duration": 60.30492,
     "end_time": "2024-12-08T09:22:31.976953",
     "exception": false,
     "start_time": "2024-12-08T09:21:31.672033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# apply analyzer to training data\n",
    "test_data_BOW_features_500 = BOW_500.transform(processed_test['combined_text'])\n",
    "# for a classificaiton problem, you need to provide both training & testing data\n",
    "X_test_data = test_data_BOW_features_500\n",
    "# È†êÊ∏¨Ê∏¨Ë©¶ÈõÜ\n",
    "y_pred = model.predict(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e39d6d3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T09:22:31.992541Z",
     "iopub.status.busy": "2024-12-08T09:22:31.992126Z",
     "iopub.status.idle": "2024-12-08T09:22:32.013570Z",
     "shell.execute_reply": "2024-12-08T09:22:32.012464Z"
    },
    "papermill": {
     "duration": 0.032078,
     "end_time": "2024-12-08T09:22:32.015967",
     "exception": false,
     "start_time": "2024-12-08T09:22:31.983889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inverse predict labels back to adjective words\n",
    "y_pred_labels = le.inverse_transform(y_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3be89df",
   "metadata": {
    "papermill": {
     "duration": 0.006639,
     "end_time": "2024-12-08T09:22:32.029952",
     "exception": false,
     "start_time": "2024-12-08T09:22:32.023313",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c0c9b1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T09:22:32.045366Z",
     "iopub.status.busy": "2024-12-08T09:22:32.044969Z",
     "iopub.status.idle": "2024-12-08T09:22:32.084537Z",
     "shell.execute_reply": "2024-12-08T09:22:32.083352Z"
    },
    "papermill": {
     "duration": 0.050315,
     "end_time": "2024-12-08T09:22:32.087251",
     "exception": false,
     "start_time": "2024-12-08T09:22:32.036936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'id': processed_test['tweet_id'],\n",
    "    'emotion': y_pred_labels\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb9038ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T09:22:32.102948Z",
     "iopub.status.busy": "2024-12-08T09:22:32.102521Z",
     "iopub.status.idle": "2024-12-08T09:22:32.629786Z",
     "shell.execute_reply": "2024-12-08T09:22:32.628762Z"
    },
    "papermill": {
     "duration": 0.537714,
     "end_time": "2024-12-08T09:22:32.632232",
     "exception": false,
     "start_time": "2024-12-08T09:22:32.094518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv('/kaggle/working/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4847c6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T09:22:32.648357Z",
     "iopub.status.busy": "2024-12-08T09:22:32.647315Z",
     "iopub.status.idle": "2024-12-08T09:22:32.659709Z",
     "shell.execute_reply": "2024-12-08T09:22:32.658651Z"
    },
    "papermill": {
     "duration": 0.022793,
     "end_time": "2024-12-08T09:22:32.661845",
     "exception": false,
     "start_time": "2024-12-08T09:22:32.639052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0x218443</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0x2939d5</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0x26289a</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867525</th>\n",
       "      <td>0x2913b4</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867529</th>\n",
       "      <td>0x2a980e</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>0x316b80</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id       emotion\n",
       "2        0x28b412  anticipation\n",
       "4        0x2de201  anticipation\n",
       "9        0x218443       sadness\n",
       "30       0x2939d5  anticipation\n",
       "33       0x26289a  anticipation\n",
       "...           ...           ...\n",
       "1867525  0x2913b4           joy\n",
       "1867529  0x2a980e       sadness\n",
       "1867530  0x316b80           joy\n",
       "1867531  0x29d0cb           joy\n",
       "1867532  0x2a6a4f       sadness\n",
       "\n",
       "[411972 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9912598,
     "sourceId": 87232,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 427.373623,
   "end_time": "2024-12-08T09:22:35.792675",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-08T09:15:28.419052",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
